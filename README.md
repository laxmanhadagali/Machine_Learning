#  Machine Learning Repository

This repository contains my complete **Machine Learning learning journey**, starting from the foundational Python data libraries to advanced machine learning algorithms and model optimization techniques.  
It is designed to document my step-by-step progress, including theoretical understanding, practical implementation, and small projects for each concept.

---

##  **What This Repository Contains**

###  **1. Python Libraries for Data Analysis**
Before diving into algorithms, it’s essential to master the core Python tools used in Data Analytics and Data Science:
- **NumPy** → Numerical computing and array operations  
- **Pandas** → Data manipulation, cleaning, and exploration  
- **Matplotlib** → Basic data visualization  
- **Seaborn** → Advanced visualization and statistical plotting  

These libraries form the backbone for handling, analyzing, and visualizing data effectively.

---

###  **2. Machine Learning Algorithms**
Once the data analysis foundation is strong, the next stage involves implementing and understanding various **Machine Learning models** using **Scikit-learn (sklearn)**.

#### **Supervised Learning**
- **Linear Regression** – Predicting continuous outcomes  
- **Logistic Regression** – Binary and multi-class classification  
- **Decision Tree** – Rule-based model for classification and regression  
- **Random Forest** – Ensemble model for improved accuracy  
- **Support Vector Machine (SVM)** – High-dimensional classification  

#### **Unsupervised Learning**
- **K-Means Clustering** – Grouping similar data points  
- **Principal Component Analysis (PCA)** – Dimensionality reduction  

---

###  **3. Model Evaluation and Optimization**
Understanding model performance is crucial. This section includes:
- Train-test split  
- Evaluation metrics (Accuracy, Precision, Recall, F1-score, ROC-AUC)  
- Cross-validation  
- Hyperparameter tuning using GridSearchCV and RandomizedSearchCV  
- Regularization (Lasso, Ridge, ElasticNet)

---

###  **4. End-to-End Mini Projects**
To apply the concepts practically, each major topic will include a small hands-on project such as:
- House Price Prediction using Linear Regression  
- Heart Deasese Prediction using Logistic Regression  
- Customer Segmentation using K-Means  
- Loan Approval Prediction using Decision Tree / Random Forest  
- Iris Flower Classification using SVM  

Each project demonstrates:
- Data cleaning and preprocessing  
- Exploratory Data Analysis (EDA)  
- Model training and evaluation  
- Visualization of insights  




##  Section 1: Python Libraries for Data Science
### Day 1 – NumPy Basics

- Introduction to NumPy
- Creating and manipulating arrays
- Array indexing, slicing, reshaping
- Mathematical operations on arrays
- Aggregation functions (sum, mean, std)
- Built-in Functions To Generate Numpy Arrays

## Day 2 – Pandas Basics

- Series and DataFrame creation
- Reading CSV/Excel files
- Data selection (loc, iloc)
- Data cleaning (missing values, duplicates)
- GroupBy and Aggregations

## Day 3 – Data Visualization

- Matplotlib: Line, bar, histogram, scatter, pie charts
- Seaborn: Pairplot, heatmap, boxplot, countplot
- Styling and labeling charts
- Mini Project: Visualizing dataset relationships (like Iris dataset)

# Section 2: Machine Learning Fundamentals
## Day 4 – Introduction to Machine Learning

- What is ML?
- Types of ML (Supervised, Unsupervised, Reinforcement)
- Understanding features and labels
- Dataset splitting (Train/Test)

## Day 5 – Linear Regression

- Simple & Multiple Linear Regression
- Using sklearn.linear_model.LinearRegression
- Model evaluation (R² Score, MAE, RMSE)
- Project: Predicting the total sales based on the money spent on Advertising

## Day 6 – Logistic Regression

- Binary classification concepts
- Confusion matrix, accuracy, precision, recall
- ROC-AUC curve
- Project: Predict whether a Person is diabetic or non-diabetic

## Day 7 – K-Means Clustering

- ncept of clustering (Unsupervised Learning)
- Choosing k (Elbow Method)
- Visualizing clusters
- Project: Species segmentation

## Day 8 – Decision Tree 

- Tree structure and splitting criteria (Gini, Entropy)
- Overfitting and post-pruning

##  Day 9 - Decision Tree & Random Forest

- Overfitting and pre-pruning
- Random Forest ensemble
- GradientBoosting
- XGBoosting

##  Day 10 - Support Vector Machine (SVM)

- Concept of hyperplane and margin
- Kernel types (linear, rbf, polynomial)
- Classification example with visualization
- Project:predicting loan approved or not based on given features

# Section 3: Feature Engineering and  Advanced Topics
## Day 10 – Model Evaluation and Optimization
- Encoding Catyegorical variables 
- Feature Transformation
- Cross Validation
- Hyperparameter Tuning (GridSearchCV, RandomizedSearchCV)
- Feature Scaling (StandardScaler, MinMaxScaler)
- Handling Imbalanced data

## Day 12 – Principal Component Analysis (PCA)

- Dimensionality reduction concept

- Explained variance and visualization




